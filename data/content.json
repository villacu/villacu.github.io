{
  "profile": {
    "name": "Emilio Villa-Cueva",
    "image": "images/me.png",
    "title": "PhD Student at MBZUAI"
  },
  "tabs": [
    {
      "id": "about",
      "title": "About",
      "content": {
        "type": "text",
        "body": "I'm a PhD student at MBZUAI, supervised by <a href='https://mbzuai.ac.ae/study/faculty/thamar-solorio/' class='bio-link'>Thamar Solorio</a> (<a href='https://ritual-mbzuai.github.io/web/' class='bio-link'>RiTUAL Lab</a>). My research focuses on building/evaluating AI that can understand human social interactions in multimodal settings, with a special focus on multimodal signals influence communication and social understanding . </p><p>I'm also interested in multilingual NLP, language adaptation of LLMs, and few-shot learning. Before this, I earned a master's degree in Computer Science from CIMAT and did a bachelors in Engineering Physics. <br><br> This semester, I am doing a research stay at <a href='https://lit.eecs.umich.edu/' class='bio-link'>LIT Lab</a> at the University of Michigan.",
        "buttons": [
          {
            "text": "Download CV",
            "icon": "<i class='fas fa-file-download'></i>",
            "link": "documents/cv.pdf",
            "class": "cv-button"
          },
          {
            "text": "Google Scholar",
            "icon": "<i class='fas fa-graduation-cap'></i>",
            "link": "https://scholar.google.com/citations?user=uYz6zaIAAAAJ",
            "class": "scholar-button"
          }
        ]
      }
    },
    {
      "id": "research",
      "title": "Research",
      "content": {
        "type": "research",
        "interests": "Multimodal Social Intelligence, Theory of Mind, Multilinguality",
        "publications": [
          {
            "title": "MOMENTS: A Comprehensive Multimodal Benchmark for Theory of Mind",
            "authors": "Emilio Villa-Cueva, SM Ahmed, Rendi Chevi, Jan Christian Blaise Cruz, Kareem Elzeky, Fermin Cristobal, Alham Fikri Aji, Skyler Wang, Rada Mihalcea, Thamar Solorio",
            "conference": "EMNLP 2025 (Findings)",
            "venue": "Empirical Methods on Natural Language Processing",
            "year": 2025,
            "paper": "https://arxiv.org/abs/2507.04415",
            "code": "",
            "dataset": "https://github.com/villacu/MoMentS",
            "project": "",
            "tldr": "Understanding Theory of Mind is essential for building socially intelligent multimodal agents capable of perceiving and interpreting human behavior. We introduce MoMentS (Multimodal Mental States), a comprehensive benchmark designed to assess the ToM capabilities of multimodal large language models (LLMs) through realistic, narrative-rich scenarios presented in short films. MoMentS includes over 2,300 multiple-choice questions spanning seven distinct ToM categories. The benchmark features long video context windows and realistic social interactions that provide deeper insight into characters' mental states. We evaluate several MLLMs and find that although vision generally improves performance, models still struggle to integrate it effectively. For audio, models that process dialogues as audio do not consistently outperform transcript-based inputs. Our findings highlight the need to improve multimodal integration and point to open challenges that must be addressed to advance AI's social understanding.",
            "image": "images/moments_viz.png",
            "bibtex": ""
          },
          {
            "title": "CaMMT: Benchmarking Culturally Aware Multimodal Machine Translation",
            "authors": "Emilio Villa-Cueva, Sholpan Bolatzhanova, Diana Turmakhan, Kareem Elzeky, Henok Biadglign Ademtew, Alham Fikri Aji, Israel Abebe Azime, Jinheon Baek, Frederico Belcavello, Fermin Cristobal, Jan Christian Blaise Cruz, Mary Dabre, Raj Dabre, Toqeer Ehsan, Naome A Etori, Fauzan Farooqui, Jiahui Geng, Guido Ivetta, Thanmay Jayakumar, Soyeong Jeong, Zheng Wei Lim, Aishik Mandal, Sofia Martinelli, Mihail Minkov Mihaylov, Daniil Orel, Aniket Pramanick, Sukannya Purkayastha, Israfel Salazar, Haiyue Song, Tiago Timponi Torrent, Debela Desalegn Yadeta, Injy Hamed, Atnafu Lambebo Tonja, Thamar Solorio",
            "conference": "EMNLP 2025 (Findings)",
            "venue": "Empirical Methods on Natural Language Processing",
            "year": 2025,
            "paper": "https://arxiv.org/abs/2505.24456",
            "code": "",
            "dataset": "",
            "project": "https://huggingface.co/datasets/villacu/cammt",
            "tldr": "Translating cultural content poses challenges for machine translation systems due to the differences in conceptualizations between cultures, where language alone may fail to convey sufficient context to capture region-specific meanings. In this work, we investigate whether images can act as cultural context in multimodal translation. We introduce CaMMT, a human-curated benchmark of over 5,800 triples of images along with parallel captions in English and regional languages. Using this dataset, we evaluate five Vision Language Models (VLMs) in text-only and text+image settings. Through automatic and human evaluations, we find that visual context generally improves translation quality, especially in handling Culturally-Specific Items (CSIs), disambiguation, and correct gender marking. By releasing CaMMT, our objective is to support broader efforts to build and evaluate multimodal translation systems that are better aligned with cultural nuance and regional variations.",
            "image": "images/cammt_viz.png",
            "bibtex": ""
          },
          {
            "title": "SHADES: Towards a multilingual assessment of stereotypes in large language models",
            "authors": "Margaret Mitchell, Giuseppe Attanasio, Ioana Baldini, Miruna Clinciu, Jordan Clive, Pieter Delobelle, Manan Dey, Sil Hamilton, Timm Dill, Jad Doughman, Ritam Dutt, Avijit Ghosh, Jessica Zosa Forde, Carolin Holtermann, Lucie-Aimée Kaffee, Tanmay Laud, Anne Lauscher, Roberto L Lopez-Davila, Maraim Masoud, Nikita Nangia, Anaelia Ovalle, Giada Pistilli, Dragomir Radev, Beatrice Savoldi, Vipul Raheja, Jeremy Qin, Esther Ploeger, Arjun Subramonian, Kaustubh Dhole, Kaiser Sun, Amirbek Djanibekov, Jonibek Mansurov, Kayo Yin, Emilio Villa Cueva, Sagnik Mukherjee, Jerry Huang, Xudong Shen, Jay Gala, Hamdan Al-Ali, Tair Djanibekov, Nurdaulet Mukhituly, Shangrui Nie, Shanya Sharma, Karolina Stańczak, Eliza Szczechla, Tiago Timponi Torrent, Deepak Tunuguntla, Marcelo Viridiano, Oskar Van Der Wal, Adina Yakefu, Aurélie Névéol, Mike Zhang, Sydney Zink, Zeerak Talat",
            "conference": "NAACL 2025",
            "venue": "Nations of the Americas Chapter of the Association for Computational Linguistics",
            "year": 2025,
            "paper": "https://aclanthology.org/2025.naacl-long.600/",
            "code": "",
            "dataset": "https://huggingface.co/datasets/LanguageShades/BiasShades",
            "project": "",
            "tldr": "",
            "image": "",
            "bibtex": ""
          },
          {
            "title": "Adaptive Cross-lingual Text Classification through In-Context One-Shot Demonstrations",
            "authors": "Emilio Villa-Cueva, Adrian López-Monroy, Fernando Sánchez Vega, Thamar Solorio",
            "conference": "NAACL 2024",
            "venue": "North American Chapter of the Association for Computational Linguistics",
            "year": 2024,
            "paper": "https://aclanthology.org/2024.naacl-long.460/",
            "code": "",
            "dataset": "",
            "project": "",
            "tldr": "In this paper, we present In-Context Cross-lingual Transfer (IC-XLT). It involves training a model to learn from context examples and subsequently adapting it during inference to a target language by prepending a One-Shot context demonstration in that language. Our results show that IC-XLT successfully leverages target-language examples to improve the cross-lingual capabilities of the evaluated mT5 model, outperforming prompt-based models in the Zero and Few-shot scenarios adapted through fine-tuning. Moreover, we show that when source-language data is limited, the fine-tuning framework employed for IC-XLT performs comparably to prompt-based fine-tuning with significantly more training data in the source language.",
            "image": "images/ic_xlt_viz.png",
            "bibtex": ""
          },
          {
            "title": "CVQA: Culturally-diverse multilingual visual question answering benchmark",
            "authors": "David Romero, Chenyang Lyu, Haryo Akbarianto Wibowo, Teresa Lynn, Injy Hamed, Aditya Nanda Kishore, Aishik Mandal, Alina Dragonetti, Artem Abzaliev, Atnafu Lambebo Tonja, Bontu Fufa Balcha, Chenxi Whitehouse, Christian Salamea, Dan John Velasco, David Ifeoluwa Adelani, David Le Meur, Emilio Villa-Cueva, Fajri Koto, Fauzan Farooqui, Frederico Belcavello, Ganzorig Batnasan, Gisela Vallejo, Grainne Caulfield, Guido Ivetta, Haiyue Song, Henok Biadglign Ademtew, Hernán Maina, Holy Lovenia, Israel Abebe Azime, Jan Christian Blaise Cruz, Jay Gala, Jiahui Geng, Jesus-German Ortiz-Barajas, Jinheon Baek, Jocelyn Dunstan, Laura Alonso Alemany, Kumaranage Ravindu Yasas Nagasinghe, Luciana Benotti, Luis Fernando d'Haro, Marcelo Viridiano, Marcos Estecha-Garitagoitia, Maria Camila Buitrago Cabrera, Mario Rodríguez-Cantelar, Mélanie Jouitteau, Mihail Mihaylov, Mohamed Fazli Mohamed Imam, Muhammad Farid Adilazuarda, Munkhjargal Gochoo, Munkh-Erdene Otgonbold, Naome Etori, Olivier Niyomugisha, Paula Mónica Silva, Pranjal Chitale, Raj Dabre, Rendi Chevi, Ruochen Zhang, Ryandito Diandaru, Samuel Cahyawijaya, Santiago Góngora, Soyeong Jeong, Sukannya Purkayastha, Tatsuki Kuribayashi, Teresa Clifford, Thanmay Jayakumar, Tiago Timponi Torrent, Toqeer Ehsan, Vladimir Araujo, Yova Kementchedjhieva, Zara Burzo, Zheng Wei Lim, Zheng Xin Yong, Oana Ignat, Joan Nwatu, Rada Mihalcea, Thamar Solorio, Alham Fikri Aji",
            "conference": "NeurIPS 2024",
            "venue": "Neural Information Processing Systems",
            "year": 2024,
            "paper": "",
            "code": "",
            "dataset": "",
            "project": "",
            "tldr": "",
            "image": "",
            "bibtex": ""
          },
          {
            "title": "PolitiBETO, a Domain-Adapted Transformer for Multi-class Political Author Profiling",
            "authors": "Emilio Villa-Cueva, Ivan González-Franco, Fernando Sanchez-Vega, Adrián Pastor López-Monroy",
            "conference": "IberLEF 2022",
            "venue": "IberLEF",
            "year": 2022,
            "paper": "",
            "code": "",
            "dataset": "",
            "project": "",
            "tldr": "",
            "image": "",
            "bibtex": ""
          }
        ]
      }
    },
    {
      "id": "contact",
      "title": "Contact",
      "content": {
        "type": "contact",
        "email": "evillacueva [at] gmail [dot] com / emilio.villa [at] mbzuai [dot] ac [dot] ae",
        "x": "evllcv",
        "linkedIn": "emilio-villa-cueva",
        "location": "Abu Dhabi, UAE"
      }
    }
  ]
}